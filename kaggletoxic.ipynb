{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "train_data=pd.read_csv(r\"C:\\Users\\harim\\Downloads\\toxic\\train\\train.csv\")\n",
    "test_data=pd.read_csv(r\"C:\\Users\\harim\\Downloads\\toxic\\test\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "abb = {\n",
    "\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\",\n",
    "\"tryin'\":\"trying\"\n",
    "}\n",
    "#defining a function to clean the data\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', '', text) # clean url\n",
    "    text = re.sub(r'#(\\w+)', '', text)   # clean hashes\n",
    "    text = re.sub(r'@(\\w+)', '', text)   # clean @\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # clean tags\n",
    "    text = re.sub(r'\\d+', '', text)      # clean digits\n",
    "    text = re.sub(r'[,!@\\'\\\"?\\.$%_&#*+-:;]', '', text)   # clean punctuation\n",
    "    text = [abb[word] if word in abb else word for word in text.split()]  #\n",
    "    \n",
    "    return text\n",
    "#applying the cleantext function to bothe train and test data\n",
    "train_data['comment_text'] = train_data['comment_text'].apply(clean_text)\n",
    "test_data['comment_text'] = test_data['comment_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train_data[\"comment_text\"].fillna(\"DUMMY_VALUE\").values\n",
    "possible_labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "targets = train_data[possible_labels].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "tk = Tokenizer(num_words = 100000, oov_token='<oov>')\n",
    "tk.fit_on_texts(train_data)\n",
    "training_sequences = tk.texts_to_sequences(sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen = 100,\n",
    "                                padding = 'pre',\n",
    "                                truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train =training_padded\n",
    "y_train=targets\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_padded,targets, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,LSTM,Bidirectional,Dropout,Embedding,GlobalMaxPooling1D,Conv1D\n",
    "from keras.models import Sequential\n",
    "\n",
    "vocab_size=len(tk.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,100))\n",
    "model.add(Bidirectional(LSTM(64,return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
    "model.add(Conv1D(128,3,padding=\"valid\"))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dense(6,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=keras.optimizers.Adam(lr=3e-4),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1746/1746 [==============================] - 833s 472ms/step - loss: 0.1703 - accuracy: 0.8554\n",
      "Epoch 2/2\n",
      "1746/1746 [==============================] - 838s 480ms/step - loss: 0.1399 - accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c4b9d1fdf0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=64,epochs=2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3491/3491 [==============================] - 261s 74ms/step - loss: 0.1411 - accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1410616785287857, 0.9942166209220886]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11175269, 0.00714377, 0.05747572, 0.00232637, 0.05602905,\n",
       "        0.00863495],\n",
       "       [0.1247071 , 0.0087392 , 0.06570429, 0.00277424, 0.06453511,\n",
       "        0.01020432],\n",
       "       [0.19008335, 0.02159321, 0.11836749, 0.00688446, 0.11042944,\n",
       "        0.02163625],\n",
       "       ...,\n",
       "       [0.19651943, 0.02343571, 0.12411308, 0.00750005, 0.11495152,\n",
       "        0.02317205],\n",
       "       [0.19644299, 0.02343783, 0.12401801, 0.0075126 , 0.11491674,\n",
       "        0.02320275],\n",
       "       [0.19232452, 0.02223459, 0.12035707, 0.00710788, 0.11209419,\n",
       "        0.02219126]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "pred=model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
